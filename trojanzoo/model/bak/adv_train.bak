self.prefix += ('_adv_train' if adv_train else '')


    #-----------------------------Adversarial Train and Validate------------------------------#
    def adv_train(self, epoch, mode='free', perturb=None, smooth=False,
                  m=8, alpha=2.0/255, epsilon=8.0/255, p=float('inf'), iteration=20, n=10,
                  adre_lambda=0.1, cat_c=10.0, cat_eta=0.005, cat_epsmax=8.0/255,
                  train_opt='full', lr_scheduler=False, validate_full=True,
                  validate_interval=10, save=True, prefix='_adv_train', **kwargs):
        if mode is None:
            return self._train(epoch, train_opt=train_opt, lr_scheduler=lr_scheduler,
                               validate_interval=validate_interval, save=save, prefix=prefix, **kwargs)

        _lr_scheduler = self.define_optimizer(
            train_opt=train_opt, lr_scheduler=True, lr_step=10, **kwargs)
        optimizer = _lr_scheduler.optimizer
        optimizer.zero_grad()

        # if mode == 'adre':
        #     # p = 2
        #     # epsilon = 4.0
        #     # m=2
        #     alpha = 2*epsilon/m
        #     iteration = m
        if perturb is None:
            perturb = 'pgd'
        if isinstance(perturb, str):
            from trojanzoo.utils.loader import get_attack
            perturb = get_attack(
                perturb, model=self, iteration=iteration, alpha=alpha, epsilon=epsilon, targeted=False, p=p, early_stop=False)
        best_acc = 95.240
        best_adv_acc = 0.01
        # _, best_acc, _ = self._validate()
        # _, best_adv_acc, _ = self.adv_validate(
        #     perturb=perturb, targeted=False, full=validate_full)
        self.train()

        losses = AverageMeter('Loss', ':.4e')
        top1 = AverageMeter('Acc@1', ':6.2f')
        top5 = AverageMeter('Acc@5', ':6.2f')

        # trainloader = self.dataset.loader['train']
        trainloader = self.dataset.get_dataloader(
            'train', full=True, shuffle=False)

        if mode == 'cat':
            cat_eps = torch.zeros(len(trainloader), dtype=torch.float)
            dirichlet = torch.distributions.dirichlet.Dirichlet(
                torch.ones(self.num_classes, dtype=torch.float))
            ce_loss = CrossEntropy()
        # end = time.time()
        for _epoch in range(epoch):
            losses.reset()
            top1.reset()
            top5.reset()
            for i, data in enumerate(trainloader):
                # data_time.update(time.time() - end)
                _input, _label = self.get_data(data, mode='train')
                if mode == 'free':
                    noise = to_tensor(torch.zeros_like(_input))
                    adv_X = _input
                    for k in range(m):
                        optimizer.zero_grad()
                        _output = self.get_logits(adv_X)
                        loss = self.criterion(_output, _label)

                        loss.backward()
                        optimizer.step()
                        optimizer.zero_grad()

                        acc1, acc5 = self.accuracy(
                            _output, _label, topk=(1, 5))
                        losses.update(loss.item(), _label.size(0))
                        top1.update(acc1[0], _label.size(0))
                        top5.update(acc5[0], _label.size(0))

                        empty_cache()
                        adv_X, _ = perturb.perturb(_input, noise=noise, target=_label,
                                                   targeted=False, iteration=1)
                        self.train()
                        self.zero_grad()
                elif mode == 'basic':
                    adv_X, _ = perturb.perturb(_input, target=_label, targeted=False,
                                               iteration=m)
                    self.train()
                    optimizer.zero_grad()
                    _output = self.get_logits(adv_X)
                    loss = self.criterion(_output, _label)

                    acc1, acc5 = self.accuracy(
                        _output, _label, topk=(1, 5))
                    losses.update(loss.item(), _label.size(0))
                    top1.update(acc1[0], _label.size(0))
                    top5.update(acc5[0], _label.size(0))

                    loss.backward()
                    optimizer.step()
                    optimizer.zero_grad()
                elif mode == 'adre':
                    adv_X, _ = perturb.perturb(_input, target=_label, targeted=False,
                                               iteration=m, randomized_smooth=smooth, n=n)
                    self.train()
                    optimizer.zero_grad()
                    _output = self.get_logits(adv_X, n=n,
                                              randomized_smooth=smooth)
                    _, indices = _output.sort(dim=-1, descending=True)
                    idx0 = to_tensor(indices[:, 0])
                    idx1 = to_tensor(indices[:, 1])
                    target = torch.where(idx0 == _label, idx1, idx0)

                    loss = self.criterion(
                        _output, _label)-adre_lambda*self.loss(adv_X, target)

                    acc1, acc5 = self.accuracy(
                        _output, _label, topk=(1, 5))
                    losses.update(loss.item(), _label.size(0))
                    top1.update(acc1[0], _label.size(0))
                    top5.update(acc5[0], _label.size(0))

                    loss.backward()
                    optimizer.step()
                    optimizer.zero_grad()
                elif mode == 'cat':
                    y = torch.zeros(len(_label), self.num_classes,
                                    dtype=torch.float)
                    y.scatter_(1, _label.unsqueeze(1), 1.0)
                    y_tild = (1-cat_c*cat_eps[i]) * \
                        (y + dirichlet.rsample([len(_label)]))
                    cat_eps[i] += cat_eta
                    adv_X, _ = perturb.perturb(_input, target=y_tild, targeted=False, alpha=cat_c*cat_eps[i], epsilon=cat_eps[i],
                                               iteration=m, loss_func=lambda _X: -ce_loss(self(_X), y_tild))
                    self.train()
                    optimizer.zero_grad()
                    _classification = self.get_class(adv_X)

                    if _classification.eq(_label).float().mean() < 0.4:
                        cat_eps[i] -= cat_eta
                    cat_eps.clamp_(max=cat_epsmax)

                    y_tild = (1-cat_c*cat_eps[i]) * \
                        (y + dirichlet.rsample([len(_label)]))
                    _output = self.get_logits(adv_X)
                    loss = ce_loss(_output, y_tild)
                    acc1, acc5 = self.accuracy(
                        _output, _label, topk=(1, 5))
                    losses.update(loss.item(), _label.size(0))
                    top1.update(acc1[0], _label.size(0))
                    top5.update(acc5[0], _label.size(0))

                    loss.backward()
                    optimizer.step()
                    optimizer.zero_grad()
                    # batch_time.update(time.time() - end)
                    # end = time.time()

                    # if i % 10 == 0:
                    #     progress.display(i)
            # if mode == 'cat':
            #     print(cat_eps.mean())
            #     print(cat_eps.min())
            print(('Epoch: [%d/%d],' % (_epoch+1, epoch)).ljust(25, ' ') +
                  'Loss: %.4f,\tTop1 Acc: %.3f,\tTop5 Acc: %.3f' % (losses.avg, top1.avg, top5.avg))
            _lr_scheduler.step()

            if validate_interval != 0:
                if (_epoch+1) % validate_interval == 0 or _epoch == epoch - 1:
                    _, cur_acc, _ = self._validate(full=validate_full)
                    _, cur_adv_acc, _ = self.adv_validate(
                        perturb=perturb, targeted=False, full=validate_full)
                    # _, cur_adv_acc, _ = self.adv_validate(perturb=perturb, targeted=True)
                    self.train()
                    if cur_adv_acc > best_adv_acc and save:
                        self.save_weights(prefix=prefix)
                        best_adv_acc = cur_adv_acc
                        print('current model saved!')
                    print('---------------------------------------------------')
        self.zero_grad()
        self.eval()

    def adv_validate(self, perturb, targeted=False, full=True,
                     loader: torch.utils.data.DataLoader = None, output=True, **kwargs):
        self.eval()
        # batch_time = AverageMeter('Time', ':6.3f')
        losses = AverageMeter('Loss', ':.4e')
        top1 = AverageMeter('Acc@1', ':6.2f')
        top5 = AverageMeter('Acc@5', ':6.2f')

        if loader is None:
            loader = self.dataset.loader['valid'] if full else self.dataset.loader['valid2']
        # progress = ProgressMeter(
        #     len(self.dataset.loader['valid']),
        #     [batch_time, losses, top1, top5],
        #     prefix='Test: ')
        # end = time.time()
        total_num = 0
        for i, data in enumerate(self.dataset.loader['valid']):
            _input, _label = self.get_data(data, mode='valid')
            target = perturb.generate_target(_input) if targeted else _label
            if len(_label) == 0:
                continue
            adv_input, _iter = perturb.perturb(
                _input, target=target, targeted=targeted)

            with torch.no_grad():
                _output = self.get_logits(adv_input)
                loss = self.criterion(_output, _label)

                # measure accuracy and record loss
                acc1, acc5 = self.accuracy(_output, _label, topk=(1, 5))
                losses.update(loss.item(), _label.size(0))
                top1.update(acc1[0], _label.size(0))
                top5.update(acc5[0], _label.size(0))

                # empty_cache()

                total_num += 1
                if total_num >= 100:
                    break

                # measure elapsed time
                # batch_time.update(time.time() - end)
                # end = time.time()

                # if i % 10 == 0:
                #     progress.display(i)

        if output:
            print(('Adv Validate '+('target' if targeted else 'untarget')).ljust(25, ' ') +
                  'Loss: %.4f,\tTop1 Acc: %.3f, \tTop5 Acc: %.3f' % (losses.avg, top1.avg, top5.avg))
        return losses.avg, top1.avg, top5.avg
    #-----------------------------------------------------------------------------------------#
